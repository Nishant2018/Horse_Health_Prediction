{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T22:51:53.259000Z","iopub.execute_input":"2023-10-01T22:51:53.259333Z","iopub.status.idle":"2023-10-01T22:51:53.575885Z","shell.execute_reply.started":"2023-10-01T22:51:53.259304Z","shell.execute_reply":"2023-10-01T22:51:53.574968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nfrom scipy import stats\nfrom sklearn.experimental import enable_hist_gradient_boosting \nfrom sklearn.ensemble import (\n    HistGradientBoostingClassifier,  # Histogram-Based Gradient Boosting Classifier\n    GradientBoostingClassifier,  # Gradient Boosting Classifier\n    AdaBoostClassifier,  # AdaBoost Classifier\n    RandomForestClassifier,  # Random Forest Classifier\n    ExtraTreesClassifier,  # Extra Trees Classifier\n    VotingClassifier,  # Ensemble Voting Classifier\n    StackingClassifier,  # Stacking Classifier\n)\nfrom xgboost import XGBClassifier  # XGBoost Classifier\nfrom lightgbm import LGBMClassifier # lightgbm Classifier\n\n# Import evaluation metrics\nfrom sklearn.metrics import f1_score","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:53.577617Z","iopub.execute_input":"2023-10-01T22:51:53.578596Z","iopub.status.idle":"2023-10-01T22:51:55.835491Z","shell.execute_reply.started":"2023-10-01T22:51:53.578562Z","shell.execute_reply":"2023-10-01T22:51:55.834552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(r\"/kaggle/input/playground-series-s3e22/train.csv\")\ntest = pd.read_csv(r\"/kaggle/input/playground-series-s3e22/test.csv\")\norigin = pd.read_csv(r\"/kaggle/input/horse-survival-dataset/horse.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:55.836972Z","iopub.execute_input":"2023-10-01T22:51:55.837632Z","iopub.status.idle":"2023-10-01T22:51:55.886467Z","shell.execute_reply.started":"2023-10-01T22:51:55.837589Z","shell.execute_reply":"2023-10-01T22:51:55.885529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:55.891519Z","iopub.execute_input":"2023-10-01T22:51:55.892316Z","iopub.status.idle":"2023-10-01T22:51:55.934673Z","shell.execute_reply.started":"2023-10-01T22:51:55.892283Z","shell.execute_reply":"2023-10-01T22:51:55.933845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"origin.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:55.938472Z","iopub.execute_input":"2023-10-01T22:51:55.940548Z","iopub.status.idle":"2023-10-01T22:51:55.971771Z","shell.execute_reply.started":"2023-10-01T22:51:55.940517Z","shell.execute_reply":"2023-10-01T22:51:55.970947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_var = [column for column in train.columns if train[column].nunique() > 10]\n\n# Create a list 'bin_var' that contains column names from 'train' where the number of unique values is exactly 2 (binary variables)\nbin_var = [column for column in train.columns if train[column].nunique() == 2]\n\n# Create a list 'cat_var' that contains specific categorical column names from 'train'\ncat_var = ['temp_of_extremities', 'peripheral_pulse', 'mucous_membrane', 'capillary_refill_time', 'pain',\n           'peristalsis', 'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux', 'rectal_exam_feces',\n           'abdomen', 'abdomo_appearance', 'lesion_2', 'surgery', 'age', 'surgical_lesion', 'lesion_3', 'cp_data']\n\n# Define the target variable, which is 'outcome'\ntarget = 'outcome'","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:55.975486Z","iopub.execute_input":"2023-10-01T22:51:55.977509Z","iopub.status.idle":"2023-10-01T22:51:56.001219Z","shell.execute_reply.started":"2023-10-01T22:51:55.977478Z","shell.execute_reply":"2023-10-01T22:51:56.000379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"is_generated\"] = 1\n\n# Add a new column 'is_generated' to the 'test' DataFrame and set all values to 1\ntest[\"is_generated\"] = 1\n\n# Add a new column 'is_generated' to the 'origin' DataFrame and set all values to 0\norigin[\"is_generated\"] = 0\n\n# Drop the 'id' column from the 'train' DataFrame\ntrain.drop('id', axis=1, inplace=True)\n\n# Drop the 'id' column from the 'test' DataFrame\ntest.drop('id', axis=1, inplace=True)\n\n# Concatenate the 'train' and 'origin' DataFrames along rows, ignoring index, and store the result in 'train_total'\ntrain_total = pd.concat([train, origin], ignore_index=True)\n\n# Remove duplicate rows from the 'train_total' DataFrame, if any\ntrain_total.drop_duplicates(inplace=True)\ntotal = pd.concat([train_total, test], ignore_index=True)\n\n# Print the shapes of the three DataFrames: 'train', 'test', and 'total'\nprint('The shape of the train data:', train.shape)\nprint('The shape of the test data:', test.shape)\nprint('The shape of the total data:', total.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:56.005492Z","iopub.execute_input":"2023-10-01T22:51:56.007942Z","iopub.status.idle":"2023-10-01T22:51:56.043382Z","shell.execute_reply.started":"2023-10-01T22:51:56.007906Z","shell.execute_reply":"2023-10-01T22:51:56.042375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def chi_squared_test(df, input_var, target_var, significance_level=0.05):\n    contingency_table = pd.crosstab(df[input_var], df[target_var])\n    chi2, p, _, _ = stats.chi2_contingency(contingency_table)\n    \n    if p < significance_level:\n        print(f'\\033[32m{input_var} has a significant relationship with the target variable.\\033[0m') \n    else:\n        print(f'\\033[31m{input_var} does not have a significant relationship with the target variable.\\033[0m')  \n\nfor i in cat_var:\n    chi_squared_test(train, i, target)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:56.047276Z","iopub.execute_input":"2023-10-01T22:51:56.049424Z","iopub.status.idle":"2023-10-01T22:51:56.222637Z","shell.execute_reply.started":"2023-10-01T22:51:56.049391Z","shell.execute_reply":"2023-10-01T22:51:56.221666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total[target] = total[target].map({'died':0,'euthanized':1,'lived':2})","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:56.226482Z","iopub.execute_input":"2023-10-01T22:51:56.228553Z","iopub.status.idle":"2023-10-01T22:51:56.237901Z","shell.execute_reply.started":"2023-10-01T22:51:56.228519Z","shell.execute_reply":"2023-10-01T22:51:56.236627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing(df, le_cols, ohe_cols):\n    \n    # Label Encoding for binary cols\n    le = LabelEncoder()    \n    for col in le_cols:\n        df[col] = le.fit_transform(df[col])\n    \n    # OneHot Encoding for category cols\n    df = pd.get_dummies(df, columns = ohe_cols)\n    \n    df[\"pain\"] = df[\"pain\"].replace('slight', 'moderate')\n    df[\"peristalsis\"] = df[\"peristalsis\"].replace('distend_small', 'normal')\n    df[\"rectal_exam_feces\"] = df[\"rectal_exam_feces\"].replace('serosanguious', 'absent')\n    df[\"nasogastric_reflux\"] = df[\"nasogastric_reflux\"].replace('slight', 'none')\n        \n    df[\"temp_of_extremities\"] = df[\"temp_of_extremities\"].fillna(\"normal\").map({'cold': 0, 'cool': 1, 'normal': 2, 'warm': 3})\n    df[\"peripheral_pulse\"] = df[\"peripheral_pulse\"].fillna(\"normal\").map({'absent': 0, 'reduced': 1, 'normal': 2, 'increased': 3})\n    df[\"capillary_refill_time\"] = df[\"capillary_refill_time\"].fillna(\"3\").map({'less_3_sec': 0, '3': 1, 'more_3_sec': 2})\n    df[\"pain\"] = df[\"pain\"].fillna(\"depressed\").map({'alert': 0, 'depressed': 1, 'moderate': 2, 'mild_pain': 3, 'severe_pain': 4, 'extreme_pain': 5})\n    df[\"peristalsis\"] = df[\"peristalsis\"].fillna(\"hypomotile\").map({'hypermotile': 0, 'normal': 1, 'hypomotile': 2, 'absent': 3})\n    df[\"abdominal_distention\"] = df[\"abdominal_distention\"].fillna(\"none\").map({'none': 0, 'slight': 1, 'moderate': 2, 'severe': 3})\n    df[\"nasogastric_tube\"] = df[\"nasogastric_tube\"].fillna(\"none\").map({'none': 0, 'slight': 1, 'significant': 2})\n    df[\"nasogastric_reflux\"] = df[\"nasogastric_reflux\"].fillna(\"none\").map({'less_1_liter': 0, 'none': 1, 'more_1_liter': 2})\n    df[\"rectal_exam_feces\"] = df[\"rectal_exam_feces\"].fillna(\"absent\").map({'absent': 0, 'decreased': 1, 'normal': 2, 'increased': 3})\n    df[\"abdomen\"] = df[\"abdomen\"].fillna(\"distend_small\").map({'normal': 0, 'other': 1, 'firm': 2,'distend_small': 3, 'distend_large': 4})\n    df[\"abdomo_appearance\"] = df[\"abdomo_appearance\"].fillna(\"serosanguious\").map({'clear': 0, 'cloudy': 1, 'serosanguious': 2})\n\n    return df    ","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:56.243478Z","iopub.execute_input":"2023-10-01T22:51:56.243725Z","iopub.status.idle":"2023-10-01T22:51:56.254335Z","shell.execute_reply.started":"2023-10-01T22:51:56.243703Z","shell.execute_reply":"2023-10-01T22:51:56.253105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total = preprocessing(total, le_cols = [\"surgery\", \"age\", \"surgical_lesion\", \"cp_data\"], ohe_cols = [\"mucous_membrane\"])","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:56.255869Z","iopub.execute_input":"2023-10-01T22:51:56.256872Z","iopub.status.idle":"2023-10-01T22:51:56.291295Z","shell.execute_reply.started":"2023-10-01T22:51:56.256820Z","shell.execute_reply":"2023-10-01T22:51:56.290431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def features_engineering(df):\n    \n    data_preprocessed = df.copy()\n    \n    # Imputer \n    cols_with_nan = df.drop(target,axis=1).columns[df.drop(target,axis=1).isna().any()].tolist()\n\n    for feature in cols_with_nan:\n        data_preprocessed[feature].fillna(data_preprocessed[feature].mode()[0], inplace=True)\n    \n    return data_preprocessed\n\ntotal = features_engineering(total)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:56.292663Z","iopub.execute_input":"2023-10-01T22:51:56.293282Z","iopub.status.idle":"2023-10-01T22:51:56.308104Z","shell.execute_reply.started":"2023-10-01T22:51:56.293249Z","shell.execute_reply":"2023-10-01T22:51:56.307318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = total[total[target].notna()]\ndf_test = total[total[target].isna()]\ndf_test.drop(target,axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:56.309324Z","iopub.execute_input":"2023-10-01T22:51:56.309897Z","iopub.status.idle":"2023-10-01T22:51:56.317663Z","shell.execute_reply.started":"2023-10-01T22:51:56.309867Z","shell.execute_reply":"2023-10-01T22:51:56.316718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_features = df_test.columns.tolist()\nbin_features = df_test.select_dtypes('bool').columns\n\ndf_train[bin_features] = df_train[bin_features].astype('int64')\ndf_test[bin_features] = df_test[bin_features].astype('int64')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:56.319360Z","iopub.execute_input":"2023-10-01T22:51:56.319967Z","iopub.status.idle":"2023-10-01T22:51:56.332883Z","shell.execute_reply.started":"2023-10-01T22:51:56.319933Z","shell.execute_reply":"2023-10-01T22:51:56.331720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:56.334454Z","iopub.execute_input":"2023-10-01T22:51:56.334810Z","iopub.status.idle":"2023-10-01T22:51:56.354138Z","shell.execute_reply.started":"2023-10-01T22:51:56.334778Z","shell.execute_reply":"2023-10-01T22:51:56.353303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def caculate_f1(y_true, y_pred):\n    return f1_score(y_true, y_pred, average = 'micro')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:56.355156Z","iopub.execute_input":"2023-10-01T22:51:56.355921Z","iopub.status.idle":"2023-10-01T22:51:56.360851Z","shell.execute_reply.started":"2023-10-01T22:51:56.355886Z","shell.execute_reply":"2023-10-01T22:51:56.359733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_baseline = LGBMClassifier(n_estimators=80,\n                     max_depth=4,\n                     random_state=42)\n\nf1_results = pd.DataFrame(columns=['Selected_Features', 'F1'])\n\ndef evaluation(df, select_features, note):\n    global f1_results\n    \n    X = df[select_features]\n    Y = df[target]\n    \n    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n    f1_scores = []\n    \n    for train_idx, test_idx in kf.split(X):\n        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n        y_train, y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n        lgbm_baseline.fit(X_train, y_train)\n        y_hat = lgbm_baseline.predict(X_test) \n        f1 = caculate_f1(y_test, y_hat)\n        f1_scores.append(f1)\n    \n    average_f1 = np.mean(f1_scores)\n    new_row = {'Selected_Features': note, 'F1': average_f1}\n    f1_results = pd.concat([f1_results, pd.DataFrame([new_row])], ignore_index=True)\n\n    print('====================================')\n    print(note)\n    print(\"Average F1:\", average_f1)\n    print('====================================')\n    return average_f1\nevaluation(df=df_train,select_features=full_features,note='Baseline')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:56.362151Z","iopub.execute_input":"2023-10-01T22:51:56.363040Z","iopub.status.idle":"2023-10-01T22:51:56.673340Z","shell.execute_reply.started":"2023-10-01T22:51:56.363008Z","shell.execute_reply":"2023-10-01T22:51:56.672709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def correlation(dataset, threshold):\n    col_corr = set()  \n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) >= threshold: \n                colname = corr_matrix.columns[i]                  \n                col_corr.add(colname)\n    return col_corr      \n\ncorr_features = correlation(df_train, 0.35)\ncorr_features","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:56.677086Z","iopub.execute_input":"2023-10-01T22:51:56.679285Z","iopub.status.idle":"2023-10-01T22:51:56.704631Z","shell.execute_reply.started":"2023-10-01T22:51:56.679256Z","shell.execute_reply":"2023-10-01T22:51:56.703586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_features = df_test.drop(['abdominal_distention',\n 'abdomo_protein',\n 'capillary_refill_time',\n 'cp_data',\n 'lesion_3',\n 'mucous_membrane_dark_cyanotic',\n 'mucous_membrane_normal_pink',\n 'packed_cell_volume',\n 'peripheral_pulse',\n 'peristalsis',\n 'rectal_exam_feces',\n 'respiratory_rate',\n 'surgical_lesion',\n 'temp_of_extremities',\n 'total_protein'],axis=1).columns.tolist()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:56.705958Z","iopub.execute_input":"2023-10-01T22:51:56.706486Z","iopub.status.idle":"2023-10-01T22:51:56.712916Z","shell.execute_reply.started":"2023-10-01T22:51:56.706457Z","shell.execute_reply":"2023-10-01T22:51:56.711897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluation(df=df_train,select_features=corr_features,note='Corr Features')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:56.714485Z","iopub.execute_input":"2023-10-01T22:51:56.715317Z","iopub.status.idle":"2023-10-01T22:51:56.968475Z","shell.execute_reply.started":"2023-10-01T22:51:56.715284Z","shell.execute_reply":"2023-10-01T22:51:56.967708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\ndef f_importance_plot(f_imp):\n    fig = plt.figure(figsize=(12, 0.20*len(f_imp)))\n    plt.title(f'Feature importances', size=16, y=1.05, \n              fontweight='bold')\n    a = sns.barplot(data=f_imp, x='imp', y='feature', linestyle=\"-\", \n                    linewidth=0.5, edgecolor=\"black\",palette='GnBu')\n    plt.xlabel('')\n    plt.xticks([])\n    plt.ylabel('')\n    plt.yticks(size=11)\n    \n    for j in ['right', 'top', 'bottom']:\n        a.spines[j].set_visible(False)\n    for j in ['left']:\n        a.spines[j].set_linewidth(0.5)\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:56.969996Z","iopub.execute_input":"2023-10-01T22:51:56.970713Z","iopub.status.idle":"2023-10-01T22:51:57.152043Z","shell.execute_reply.started":"2023-10-01T22:51:56.970678Z","shell.execute_reply":"2023-10-01T22:51:57.151121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = LGBMClassifier(n_estimators=1000,\n                     max_depth=10,\n                     random_state=42)\nclf.fit(df_train.drop(target,axis=1), df_train[target])\n\nf_imp_df = pd.DataFrame({'feature': df_train.drop(target,axis=1).columns, 'imp': clf.feature_importances_})\nf_imp_df.sort_values(by='imp',ascending=False,inplace=True)\nf_importance_plot(f_imp_df)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:57.153228Z","iopub.execute_input":"2023-10-01T22:51:57.153744Z","iopub.status.idle":"2023-10-01T22:51:59.660584Z","shell.execute_reply.started":"2023-10-01T22:51:57.153709Z","shell.execute_reply":"2023-10-01T22:51:59.659689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_feature_num = 30\nbest_score = 0.7392406127690802\nprint(f'Best feature number is Top {best_feature_num}, Best score is {best_score}')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:59.661560Z","iopub.execute_input":"2023-10-01T22:51:59.661888Z","iopub.status.idle":"2023-10-01T22:51:59.667815Z","shell.execute_reply.started":"2023-10-01T22:51:59.661858Z","shell.execute_reply":"2023-10-01T22:51:59.666536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_features = f_imp_df.head(best_feature_num).feature.to_list()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:59.669494Z","iopub.execute_input":"2023-10-01T22:51:59.670428Z","iopub.status.idle":"2023-10-01T22:51:59.679597Z","shell.execute_reply.started":"2023-10-01T22:51:59.670394Z","shell.execute_reply":"2023-10-01T22:51:59.678939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_train[best_features]\ny = df_train[target]\n\ntest_df = df_test[best_features]\n\nX","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:59.680697Z","iopub.execute_input":"2023-10-01T22:51:59.681592Z","iopub.status.idle":"2023-10-01T22:51:59.714513Z","shell.execute_reply.started":"2023-10-01T22:51:59.681537Z","shell.execute_reply":"2023-10-01T22:51:59.713538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.metrics import f1_score\n\n\nhist_model = HistGradientBoostingClassifier(\n    max_depth=4,           # Adjust the maximum depth of each tree\n    max_iter=80,          # Adjust the number of boosting iterations\n    learning_rate=0.1,     # Adjust the learning rate\n    random_state=42,   \n    scoring='f1_micro',          \n    max_leaf_nodes = 21,\n    l2_regularization = 0.1,\n)\n\nhist_model.fit(X, y)\nprint(f\"HistGradientBoosting Model: F1 Score (Micro-Average) = {f1_score(y, hist_model.predict(X), average='micro') * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:51:59.715932Z","iopub.execute_input":"2023-10-01T22:51:59.716475Z","iopub.status.idle":"2023-10-01T22:52:00.132386Z","shell.execute_reply.started":"2023-10-01T22:51:59.716442Z","shell.execute_reply":"2023-10-01T22:52:00.131521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv(r\"/kaggle/input/playground-series-s3e22/sample_submission.csv\")\nsubmission = hist_model.predict(test_df)\nsample_submission['outcome'] = submission\nsample_submission","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:52:00.133729Z","iopub.execute_input":"2023-10-01T22:52:00.134321Z","iopub.status.idle":"2023-10-01T22:52:00.168373Z","shell.execute_reply.started":"2023-10-01T22:52:00.134286Z","shell.execute_reply":"2023-10-01T22:52:00.167648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outcome_mapping = {0.0: 'died', 1.0: 'euthanized', 2.0: 'lived'}\n\n# Map the values in the \"outcome\" column using the dictionary\nsample_submission['outcome'] = sample_submission['outcome'].map(outcome_mapping)\nsample_submission","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:52:00.172444Z","iopub.execute_input":"2023-10-01T22:52:00.172925Z","iopub.status.idle":"2023-10-01T22:52:00.186467Z","shell.execute_reply.started":"2023-10-01T22:52:00.172893Z","shell.execute_reply":"2023-10-01T22:52:00.185207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T22:52:00.187863Z","iopub.execute_input":"2023-10-01T22:52:00.188425Z","iopub.status.idle":"2023-10-01T22:52:00.196882Z","shell.execute_reply.started":"2023-10-01T22:52:00.188395Z","shell.execute_reply":"2023-10-01T22:52:00.195860Z"},"trusted":true},"execution_count":null,"outputs":[]}]}